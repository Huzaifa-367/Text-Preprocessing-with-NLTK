{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvGAqbK3KLa4",
        "outputId": "d957d4a3-3143-4fc5-a2f7-8ef2d75d7dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 => Original Text: i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n",
            "Stemmed Tokens: ['feel', 'aw', 'job', 'get', 'posit', 'succeed', 'happen']\n",
            "Lemmatized Tokens: ['feel', 'awful', 'job', 'get', 'position', 'succeed', 'happen']\n",
            "\n",
            "1 => Original Text: im alone i feel awful\n",
            "Stemmed Tokens: ['im', 'alon', 'feel', 'aw']\n",
            "Lemmatized Tokens: ['im', 'alone', 'feel', 'awful']\n",
            "\n",
            "2 => Original Text: ive probably mentioned this before but i really do feel proud of myself for actually keeping up with my new years resolution of monthly and weekly goals\n",
            "Stemmed Tokens: ['ive', 'probabl', 'mention', 'realli', 'feel', 'proud', 'actual', 'keep', 'new', 'year', 'resolut', 'monthli', 'weekli', 'goal']\n",
            "Lemmatized Tokens: ['ive', 'probably', 'mentioned', 'really', 'feel', 'proud', 'actually', 'keeping', 'new', 'year', 'resolution', 'monthly', 'weekly', 'goal']\n",
            "\n",
            "3 => Original Text: i was feeling a little low few days back\n",
            "Stemmed Tokens: ['feel', 'littl', 'low', 'day', 'back']\n",
            "Lemmatized Tokens: ['feeling', 'little', 'low', 'day', 'back']\n",
            "\n",
            "4 => Original Text: i beleive that i am much more sensitive to other peoples feelings and tend to be more compassionate\n",
            "Stemmed Tokens: ['beleiv', 'much', 'sensit', 'peopl', 'feel', 'tend', 'compassion']\n",
            "Lemmatized Tokens: ['beleive', 'much', 'sensitive', 'people', 'feeling', 'tend', 'compassionate']\n",
            "\n",
            "5 => Original Text: i find myself frustrated with christians because i feel that there is constantly a talk about loving one another being there for each other and praying for each other and i have seen that this is not always the case\n",
            "Stemmed Tokens: ['find', 'frustrat', 'christian', 'feel', 'constantli', 'talk', 'love', 'one', 'anoth', 'pray', 'seen', 'alway', 'case']\n",
            "Lemmatized Tokens: ['find', 'frustrated', 'christian', 'feel', 'constantly', 'talk', 'loving', 'one', 'another', 'praying', 'seen', 'always', 'case']\n",
            "\n",
            "6 => Original Text: i am one of those people who feels like going to the gym is only worthwhile if you can be there for an hour or more\n",
            "Stemmed Tokens: ['one', 'peopl', 'feel', 'like', 'go', 'gym', 'worthwhil', 'hour']\n",
            "Lemmatized Tokens: ['one', 'people', 'feel', 'like', 'going', 'gym', 'worthwhile', 'hour']\n",
            "\n",
            "7 => Original Text: i feel especially pleased about this as this has been a long time coming\n",
            "Stemmed Tokens: ['feel', 'especi', 'pleas', 'long', 'time', 'come']\n",
            "Lemmatized Tokens: ['feel', 'especially', 'pleased', 'long', 'time', 'coming']\n",
            "\n",
            "8 => Original Text: i was struggling with these awful feelings and was saying such sweet things about not deserving my and my sisters friendship and we agreed well she was in her car just starting to drive away when she reached out her hand\n",
            "Stemmed Tokens: ['struggl', 'aw', 'feel', 'say', 'sweet', 'thing', 'deserv', 'sister', 'friendship', 'agre', 'well', 'car', 'start', 'drive', 'away', 'reach', 'hand']\n",
            "Lemmatized Tokens: ['struggling', 'awful', 'feeling', 'saying', 'sweet', 'thing', 'deserving', 'sister', 'friendship', 'agreed', 'well', 'car', 'starting', 'drive', 'away', 'reached', 'hand']\n",
            "\n",
            "9 => Original Text: i feel so enraged but helpless at the same time\n",
            "Stemmed Tokens: ['feel', 'enrag', 'helpless', 'time']\n",
            "Lemmatized Tokens: ['feel', 'enraged', 'helpless', 'time']\n",
            "\n",
            "10 => Original Text: i said feeling a bit rebellious\n",
            "Stemmed Tokens: ['said', 'feel', 'bit', 'rebelli']\n",
            "Lemmatized Tokens: ['said', 'feeling', 'bit', 'rebellious']\n",
            "\n",
            "11 => Original Text: i also feel disillusioned that someone who claimed to value the truth as i do was a fraud\n",
            "Stemmed Tokens: ['also', 'feel', 'disillus', 'someon', 'claim', 'valu', 'truth', 'fraud']\n",
            "Lemmatized Tokens: ['also', 'feel', 'disillusioned', 'someone', 'claimed', 'value', 'truth', 'fraud']\n",
            "\n",
            "12 => Original Text: i mean is on this stupid trip of making the great album when things are going well i feel ecstatic\n",
            "Stemmed Tokens: ['mean', 'stupid', 'trip', 'make', 'great', 'album', 'thing', 'go', 'well', 'feel', 'ecstat']\n",
            "Lemmatized Tokens: ['mean', 'stupid', 'trip', 'making', 'great', 'album', 'thing', 'going', 'well', 'feel', 'ecstatic']\n",
            "\n",
            "13 => Original Text: i woke up feeling particularly vile tried to ignore it but it got worse and worse and worse\n",
            "Stemmed Tokens: ['woke', 'feel', 'particularli', 'vile', 'tri', 'ignor', 'got', 'wors', 'wors', 'wors']\n",
            "Lemmatized Tokens: ['woke', 'feeling', 'particularly', 'vile', 'tried', 'ignore', 'got', 'worse', 'worse', 'worse']\n",
            "\n",
            "14 => Original Text: i could feel the vile moth burrowing its way into my brain seeking my brain as a means to control and enslave me just as those nasty bug things did to chekov in star trek the wrath of khan\n",
            "Stemmed Tokens: ['could', 'feel', 'vile', 'moth', 'burrow', 'way', 'brain', 'seek', 'brain', 'mean', 'control', 'enslav', 'nasti', 'bug', 'thing', 'chekov', 'star', 'trek', 'wrath', 'khan']\n",
            "Lemmatized Tokens: ['could', 'feel', 'vile', 'moth', 'burrowing', 'way', 'brain', 'seeking', 'brain', 'mean', 'control', 'enslave', 'nasty', 'bug', 'thing', 'chekov', 'star', 'trek', 'wrath', 'khan']\n",
            "\n",
            "15 => Original Text: i know its just doing its job and doesnt actually have thoughts or feelings but that little jingle it does at the end of every cycle just makes it seem so excited to have done another load that it cant help but sing about it\n",
            "Stemmed Tokens: ['know', 'job', 'doesnt', 'actual', 'thought', 'feel', 'littl', 'jingl', 'end', 'everi', 'cycl', 'make', 'seem', 'excit', 'done', 'anoth', 'load', 'cant', 'help', 'sing']\n",
            "Lemmatized Tokens: ['know', 'job', 'doesnt', 'actually', 'thought', 'feeling', 'little', 'jingle', 'end', 'every', 'cycle', 'make', 'seem', 'excited', 'done', 'another', 'load', 'cant', 'help', 'sing']\n",
            "\n",
            "16 => Original Text: i wish you knew every word i write i write for you and i think it s useless because i m just heartless this feeling is empty in it s w\n",
            "Stemmed Tokens: ['wish', 'knew', 'everi', 'word', 'write', 'write', 'think', 'useless', 'heartless', 'feel', 'empti', 'w']\n",
            "Lemmatized Tokens: ['wish', 'knew', 'every', 'word', 'write', 'write', 'think', 'useless', 'heartless', 'feeling', 'empty', 'w']\n",
            "\n",
            "17 => Original Text: i feel weird knowing mine died when i wasn t around\n",
            "Stemmed Tokens: ['feel', 'weird', 'know', 'mine', 'die', 'around']\n",
            "Lemmatized Tokens: ['feel', 'weird', 'knowing', 'mine', 'died', 'around']\n",
            "\n",
            "18 => Original Text: i feel assured that there is no such thing as ultimate forgetting traces once impressed upon the memory are indestructible\n",
            "Stemmed Tokens: ['feel', 'assur', 'thing', 'ultim', 'forget', 'trace', 'impress', 'upon', 'memori', 'indestruct']\n",
            "Lemmatized Tokens: ['feel', 'assured', 'thing', 'ultimate', 'forgetting', 'trace', 'impressed', 'upon', 'memory', 'indestructible']\n",
            "\n",
            "19 => Original Text: i feel blessed everyday for our little man and love to watch him grow\n",
            "Stemmed Tokens: ['feel', 'bless', 'everyday', 'littl', 'man', 'love', 'watch', 'grow']\n",
            "Lemmatized Tokens: ['feel', 'blessed', 'everyday', 'little', 'man', 'love', 'watch', 'grow']\n",
            "\n",
            "20 => Original Text: i feel exhausted when i go home but i am always glad that i am learning new things and i can help others learn as well\n",
            "Stemmed Tokens: ['feel', 'exhaust', 'go', 'home', 'alway', 'glad', 'learn', 'new', 'thing', 'help', 'other', 'learn', 'well']\n",
            "Lemmatized Tokens: ['feel', 'exhausted', 'go', 'home', 'always', 'glad', 'learning', 'new', 'thing', 'help', 'others', 'learn', 'well']\n",
            "\n",
            "21 => Original Text: i stil can see kaibas face on every tv screen still see amateur duelists prowling the good side of city and still feel the urge to throttle all those idiotic mortals that dare to look me in the eye\n",
            "Stemmed Tokens: ['stil', 'see', 'kaiba', 'face', 'everi', 'tv', 'screen', 'still', 'see', 'amateur', 'duelist', 'prowl', 'good', 'side', 'citi', 'still', 'feel', 'urg', 'throttl', 'idiot', 'mortal', 'dare', 'look', 'eye']\n",
            "Lemmatized Tokens: ['stil', 'see', 'kaibas', 'face', 'every', 'tv', 'screen', 'still', 'see', 'amateur', 'duelist', 'prowling', 'good', 'side', 'city', 'still', 'feel', 'urge', 'throttle', 'idiotic', 'mortal', 'dare', 'look', 'eye']\n",
            "\n",
            "22 => Original Text: i don t like to feel uncomfortable with being alone and being quiet\n",
            "Stemmed Tokens: ['like', 'feel', 'uncomfort', 'alon', 'quiet']\n",
            "Lemmatized Tokens: ['like', 'feel', 'uncomfortable', 'alone', 'quiet']\n",
            "\n",
            "23 => Original Text: i was left kinda feeling stupid and insecure\n",
            "Stemmed Tokens: ['left', 'kinda', 'feel', 'stupid', 'insecur']\n",
            "Lemmatized Tokens: ['left', 'kinda', 'feeling', 'stupid', 'insecure']\n",
            "\n",
            "24 => Original Text: i alternate between feeling sympathetic toward humanity and being a misanthrope\n",
            "Stemmed Tokens: ['altern', 'feel', 'sympathet', 'toward', 'human', 'misanthrop']\n",
            "Lemmatized Tokens: ['alternate', 'feeling', 'sympathetic', 'toward', 'humanity', 'misanthrope']\n",
            "\n",
            "25 => Original Text: i have a pretty bad feeling the last two books will be rushed in terms of story\n",
            "Stemmed Tokens: ['pretti', 'bad', 'feel', 'last', 'two', 'book', 'rush', 'term', 'stori']\n",
            "Lemmatized Tokens: ['pretty', 'bad', 'feeling', 'last', 'two', 'book', 'rushed', 'term', 'story']\n",
            "\n",
            "26 => Original Text: i sincerely believe that every client celebrity or not deserves my full attention and leaves feeling more glamorous than when they arrived\n",
            "Stemmed Tokens: ['sincer', 'believ', 'everi', 'client', 'celebr', 'deserv', 'full', 'attent', 'leav', 'feel', 'glamor', 'arriv']\n",
            "Lemmatized Tokens: ['sincerely', 'believe', 'every', 'client', 'celebrity', 'deserves', 'full', 'attention', 'leaf', 'feeling', 'glamorous', 'arrived']\n",
            "\n",
            "27 => Original Text: i don t feel comfortable around you\n",
            "Stemmed Tokens: ['feel', 'comfort', 'around']\n",
            "Lemmatized Tokens: ['feel', 'comfortable', 'around']\n",
            "\n",
            "28 => Original Text: i am happy that you don t feel as burdened and consumed as i do\n",
            "Stemmed Tokens: ['happi', 'feel', 'burden', 'consum']\n",
            "Lemmatized Tokens: ['happy', 'feel', 'burdened', 'consumed']\n",
            "\n",
            "29 => Original Text: i am still here i am not dead yet but these things can not be said without feeling humiliated\n",
            "Stemmed Tokens: ['still', 'dead', 'yet', 'thing', 'said', 'without', 'feel', 'humili']\n",
            "Lemmatized Tokens: ['still', 'dead', 'yet', 'thing', 'said', 'without', 'feeling', 'humiliated']\n",
            "\n",
            "30 => Original Text: i have been continually surprised at how much less i need to eat to feel truly satisfied if im eating good food and sitting down for a whole lovely little experience at each meal satisfying the soul as well as the stomach\n",
            "Stemmed Tokens: ['continu', 'surpris', 'much', 'less', 'need', 'eat', 'feel', 'truli', 'satisfi', 'im', 'eat', 'good', 'food', 'sit', 'whole', 'love', 'littl', 'experi', 'meal', 'satisfi', 'soul', 'well', 'stomach']\n",
            "Lemmatized Tokens: ['continually', 'surprised', 'much', 'le', 'need', 'eat', 'feel', 'truly', 'satisfied', 'im', 'eating', 'good', 'food', 'sitting', 'whole', 'lovely', 'little', 'experience', 'meal', 'satisfying', 'soul', 'well', 'stomach']\n",
            "\n",
            "31 => Original Text: i pretty much waddled out of the hospital feeling weird lightheaded but ok\n",
            "Stemmed Tokens: ['pretti', 'much', 'waddl', 'hospit', 'feel', 'weird', 'lighthead', 'ok']\n",
            "Lemmatized Tokens: ['pretty', 'much', 'waddled', 'hospital', 'feeling', 'weird', 'lightheaded', 'ok']\n",
            "\n",
            "32 => Original Text: i apologize to him almost every day for my lack of faith and i ask him to give me more because i feel uncertain about my future here in kiev\n",
            "Stemmed Tokens: ['apolog', 'almost', 'everi', 'day', 'lack', 'faith', 'ask', 'give', 'feel', 'uncertain', 'futur', 'kiev']\n",
            "Lemmatized Tokens: ['apologize', 'almost', 'every', 'day', 'lack', 'faith', 'ask', 'give', 'feel', 'uncertain', 'future', 'kiev']\n",
            "\n",
            "33 => Original Text: i am still searching for direction but at least now i feel slightly more assured more hopeful\n",
            "Stemmed Tokens: ['still', 'search', 'direct', 'least', 'feel', 'slightli', 'assur', 'hope']\n",
            "Lemmatized Tokens: ['still', 'searching', 'direction', 'least', 'feel', 'slightly', 'assured', 'hopeful']\n",
            "\n",
            "34 => Original Text: i am so angry that i feel like i have to go through life not being as carefree as i want to be\n",
            "Stemmed Tokens: ['angri', 'feel', 'like', 'go', 'life', 'carefre', 'want']\n",
            "Lemmatized Tokens: ['angry', 'feel', 'like', 'go', 'life', 'carefree', 'want']\n",
            "\n",
            "35 => Original Text: i feel passionate about today because of him\n",
            "Stemmed Tokens: ['feel', 'passion', 'today']\n",
            "Lemmatized Tokens: ['feel', 'passionate', 'today']\n",
            "\n",
            "36 => Original Text: i am only having day a week where i am feeling depressed or seriously anxious\n",
            "Stemmed Tokens: ['day', 'week', 'feel', 'depress', 'serious', 'anxiou']\n",
            "Lemmatized Tokens: ['day', 'week', 'feeling', 'depressed', 'seriously', 'anxious']\n",
            "\n",
            "37 => Original Text: article published\n",
            "Stemmed Tokens: ['articl', 'publish']\n",
            "Lemmatized Tokens: ['article', 'published']\n",
            "\n",
            "38 => Original Text: i see things so clearly and with so much depth peace that it makes me feel unsure\n",
            "Stemmed Tokens: ['see', 'thing', 'clearli', 'much', 'depth', 'peac', 'make', 'feel', 'unsur']\n",
            "Lemmatized Tokens: ['see', 'thing', 'clearly', 'much', 'depth', 'peace', 'make', 'feel', 'unsure']\n",
            "\n",
            "39 => Original Text: i feel myself relax a little he wouldn t be this friendly if he was going to tear me off a strip but my mind is working overtime trying to work out what he does want\n",
            "Stemmed Tokens: ['feel', 'relax', 'littl', 'friendli', 'go', 'tear', 'strip', 'mind', 'work', 'overtim', 'tri', 'work', 'want']\n",
            "Lemmatized Tokens: ['feel', 'relax', 'little', 'friendly', 'going', 'tear', 'strip', 'mind', 'working', 'overtime', 'trying', 'work', 'want']\n",
            "\n",
            "40 => Original Text: i feel doubtful about my place in the world of technology and the applicable value of the work i do i often find it helpful to think about doug engelbart listening to him describe in one of many interviews his goals the genesis of his goals and his dogged perseverance toward meeting his plan\n",
            "Stemmed Tokens: ['feel', 'doubt', 'place', 'world', 'technolog', 'applic', 'valu', 'work', 'often', 'find', 'help', 'think', 'doug', 'engelbart', 'listen', 'describ', 'one', 'mani', 'interview', 'goal', 'genesi', 'goal', 'dog', 'persever', 'toward', 'meet', 'plan']\n",
            "Lemmatized Tokens: ['feel', 'doubtful', 'place', 'world', 'technology', 'applicable', 'value', 'work', 'often', 'find', 'helpful', 'think', 'doug', 'engelbart', 'listening', 'describe', 'one', 'many', 'interview', 'goal', 'genesis', 'goal', 'dogged', 'perseverance', 'toward', 'meeting', 'plan']\n",
            "\n",
            "41 => Original Text: im feeling rotten i dont post much new material that doesnt mean you shouldnt be reading when youre feeling rotten\n",
            "Stemmed Tokens: ['im', 'feel', 'rotten', 'dont', 'post', 'much', 'new', 'materi', 'doesnt', 'mean', 'shouldnt', 'read', 'your', 'feel', 'rotten']\n",
            "Lemmatized Tokens: ['im', 'feeling', 'rotten', 'dont', 'post', 'much', 'new', 'material', 'doesnt', 'mean', 'shouldnt', 'reading', 'youre', 'feeling', 'rotten']\n",
            "\n",
            "42 => Original Text: i have a feeling that theyre probably not going to be thrilled with me\n",
            "Stemmed Tokens: ['feel', 'theyr', 'probabl', 'go', 'thrill']\n",
            "Lemmatized Tokens: ['feeling', 'theyre', 'probably', 'going', 'thrilled']\n",
            "\n",
            "43 => Original Text: ive been feeling pretty shitty and been in a pretty shitty mood the past few days\n",
            "Stemmed Tokens: ['ive', 'feel', 'pretti', 'shitti', 'pretti', 'shitti', 'mood', 'past', 'day']\n",
            "Lemmatized Tokens: ['ive', 'feeling', 'pretty', 'shitty', 'pretty', 'shitty', 'mood', 'past', 'day']\n",
            "\n",
            "44 => Original Text: i cant even imagine how my mom and her three younger sisters must feel i think the weird thing about death is that from an early age we associate it with something evil and tragic\n",
            "Stemmed Tokens: ['cant', 'even', 'imagin', 'mom', 'three', 'younger', 'sister', 'must', 'feel', 'think', 'weird', 'thing', 'death', 'earli', 'age', 'associ', 'someth', 'evil', 'tragic']\n",
            "Lemmatized Tokens: ['cant', 'even', 'imagine', 'mom', 'three', 'younger', 'sister', 'must', 'feel', 'think', 'weird', 'thing', 'death', 'early', 'age', 'associate', 'something', 'evil', 'tragic']\n",
            "\n",
            "45 => Original Text: i feel glad i am on the side of the law and the only journey about to start was our weekend sojourn to the city of pines\n",
            "Stemmed Tokens: ['feel', 'glad', 'side', 'law', 'journey', 'start', 'weekend', 'sojourn', 'citi', 'pine']\n",
            "Lemmatized Tokens: ['feel', 'glad', 'side', 'law', 'journey', 'start', 'weekend', 'sojourn', 'city', 'pine']\n",
            "\n",
            "46 => Original Text: i will most likely feel overwhelmed and exhausted again\n",
            "Stemmed Tokens: ['like', 'feel', 'overwhelm', 'exhaust']\n",
            "Lemmatized Tokens: ['likely', 'feel', 'overwhelmed', 'exhausted']\n",
            "\n",
            "47 => Original Text: i can feel myself reaching out extending through time and space to touch my beloved\n",
            "Stemmed Tokens: ['feel', 'reach', 'extend', 'time', 'space', 'touch', 'belov']\n",
            "Lemmatized Tokens: ['feel', 'reaching', 'extending', 'time', 'space', 'touch', 'beloved']\n",
            "\n",
            "48 => Original Text: im looking right now so desperately looking for a creative project that i feel like i have had a hand in that i need to sit and write my fucking mother fucker of a fuckity fuckers fucked play before i feel satisfied doing anything else\n",
            "Stemmed Tokens: ['im', 'look', 'right', 'desper', 'look', 'creativ', 'project', 'feel', 'like', 'hand', 'need', 'sit', 'write', 'fuck', 'mother', 'fucker', 'fuckiti', 'fucker', 'fuck', 'play', 'feel', 'satisfi', 'anyth', 'els']\n",
            "Lemmatized Tokens: ['im', 'looking', 'right', 'desperately', 'looking', 'creative', 'project', 'feel', 'like', 'hand', 'need', 'sit', 'write', 'fucking', 'mother', 'fucker', 'fuckity', 'fucker', 'fucked', 'play', 'feel', 'satisfied', 'anything', 'else']\n",
            "\n",
            "49 => Original Text: i am really hoping to get to target soon and i am so glad im feeling more positive this week\n",
            "Stemmed Tokens: ['realli', 'hope', 'get', 'target', 'soon', 'glad', 'im', 'feel', 'posit', 'week']\n",
            "Lemmatized Tokens: ['really', 'hoping', 'get', 'target', 'soon', 'glad', 'im', 'feeling', 'positive', 'week']\n",
            "\n",
            "50 => Original Text: i dont know if i feel appreciative of all the talent out there or depressed that i suck at this so much\n",
            "Stemmed Tokens: ['dont', 'know', 'feel', 'appreci', 'talent', 'depress', 'suck', 'much']\n",
            "Lemmatized Tokens: ['dont', 'know', 'feel', 'appreciative', 'talent', 'depressed', 'suck', 'much']\n",
            "\n",
            "51 => Original Text: i feel he will be ok with out it\n",
            "Stemmed Tokens: ['feel', 'ok']\n",
            "Lemmatized Tokens: ['feel', 'ok']\n",
            "\n",
            "52 => Original Text: i tend to stop breathing when i m feeling stressed\n",
            "Stemmed Tokens: ['tend', 'stop', 'breath', 'feel', 'stress']\n",
            "Lemmatized Tokens: ['tend', 'stop', 'breathing', 'feeling', 'stressed']\n",
            "\n",
            "53 => Original Text: i feel sickened by and disgusted with the sins of man despite my divinity i feel sickened by and disgusted with the sins of man\n",
            "Stemmed Tokens: ['feel', 'sicken', 'disgust', 'sin', 'man', 'despit', 'divin', 'feel', 'sicken', 'disgust', 'sin', 'man']\n",
            "Lemmatized Tokens: ['feel', 'sickened', 'disgusted', 'sin', 'man', 'despite', 'divinity', 'feel', 'sickened', 'disgusted', 'sin', 'man']\n",
            "\n",
            "54 => Original Text: i feel that i have nothing smart or interesting to write about these days\n",
            "Stemmed Tokens: ['feel', 'noth', 'smart', 'interest', 'write', 'day']\n",
            "Lemmatized Tokens: ['feel', 'nothing', 'smart', 'interesting', 'write', 'day']\n",
            "\n",
            "55 => Original Text: i feel blessed and grateful today\n",
            "Stemmed Tokens: ['feel', 'bless', 'grate', 'today']\n",
            "Lemmatized Tokens: ['feel', 'blessed', 'grateful', 'today']\n",
            "\n",
            "56 => Original Text: i am not feeling very compassionate towards those that need our help i just want them to fix their own problems so i dont have to figure out what parts they need or how long it will take to get the job done or is this an emergency\n",
            "Stemmed Tokens: ['feel', 'compassion', 'toward', 'need', 'help', 'want', 'fix', 'problem', 'dont', 'figur', 'part', 'need', 'long', 'take', 'get', 'job', 'done', 'emerg']\n",
            "Lemmatized Tokens: ['feeling', 'compassionate', 'towards', 'need', 'help', 'want', 'fix', 'problem', 'dont', 'figure', 'part', 'need', 'long', 'take', 'get', 'job', 'done', 'emergency']\n",
            "\n",
            "57 => Original Text: i had my week appointment yesterday and left feeling a little defeated\n",
            "Stemmed Tokens: ['week', 'appoint', 'yesterday', 'left', 'feel', 'littl', 'defeat']\n",
            "Lemmatized Tokens: ['week', 'appointment', 'yesterday', 'left', 'feeling', 'little', 'defeated']\n",
            "\n",
            "58 => Original Text: i know it isnt true but sometimes i feel like the most unimportant insignificant person on the face of the earth\n",
            "Stemmed Tokens: ['know', 'isnt', 'true', 'sometim', 'feel', 'like', 'unimport', 'insignific', 'person', 'face', 'earth']\n",
            "Lemmatized Tokens: ['know', 'isnt', 'true', 'sometimes', 'feel', 'like', 'unimportant', 'insignificant', 'person', 'face', 'earth']\n",
            "\n",
            "59 => Original Text: i feel so numb to everything right now and its hard to express exactly what i feel but we went for a little harrison walk nonetheless to clear our heads\n",
            "Stemmed Tokens: ['feel', 'numb', 'everyth', 'right', 'hard', 'express', 'exactli', 'feel', 'went', 'littl', 'harrison', 'walk', 'nonetheless', 'clear', 'head']\n",
            "Lemmatized Tokens: ['feel', 'numb', 'everything', 'right', 'hard', 'express', 'exactly', 'feel', 'went', 'little', 'harrison', 'walk', 'nonetheless', 'clear', 'head']\n",
            "\n",
            "60 => Original Text: i feel for you makes me brave\n",
            "Stemmed Tokens: ['feel', 'make', 'brave']\n",
            "Lemmatized Tokens: ['feel', 'make', 'brave']\n",
            "\n",
            "61 => Original Text: i am feeling incredibly thankful for this year my children\n",
            "Stemmed Tokens: ['feel', 'incred', 'thank', 'year', 'children']\n",
            "Lemmatized Tokens: ['feeling', 'incredibly', 'thankful', 'year', 'child']\n",
            "\n",
            "62 => Original Text: i write this i m sipping on a martini which is probably why i m feeling so generous\n",
            "Stemmed Tokens: ['write', 'sip', 'martini', 'probabl', 'feel', 'gener']\n",
            "Lemmatized Tokens: ['write', 'sipping', 'martini', 'probably', 'feeling', 'generous']\n",
            "\n",
            "63 => Original Text: i would recommend watching them to feel amazed and inspired\n",
            "Stemmed Tokens: ['would', 'recommend', 'watch', 'feel', 'amaz', 'inspir']\n",
            "Lemmatized Tokens: ['would', 'recommend', 'watching', 'feel', 'amazed', 'inspired']\n",
            "\n",
            "64 => Original Text: i can t really put into eloquent words what i m trying to say i just feel listless and useless and meaningless as though i ve failed in life\n",
            "Stemmed Tokens: ['realli', 'put', 'eloqu', 'word', 'tri', 'say', 'feel', 'listless', 'useless', 'meaningless', 'though', 'fail', 'life']\n",
            "Lemmatized Tokens: ['really', 'put', 'eloquent', 'word', 'trying', 'say', 'feel', 'listless', 'useless', 'meaningless', 'though', 'failed', 'life']\n",
            "\n",
            "65 => Original Text: i feel that i have a really funny side that i would like people to see\n",
            "Stemmed Tokens: ['feel', 'realli', 'funni', 'side', 'would', 'like', 'peopl', 'see']\n",
            "Lemmatized Tokens: ['feel', 'really', 'funny', 'side', 'would', 'like', 'people', 'see']\n",
            "\n",
            "66 => Original Text: i already feel awful about what happened and i actually needed to hear you say everything you just said more than anything else in the whole world\n",
            "Stemmed Tokens: ['alreadi', 'feel', 'aw', 'happen', 'actual', 'need', 'hear', 'say', 'everyth', 'said', 'anyth', 'els', 'whole', 'world']\n",
            "Lemmatized Tokens: ['already', 'feel', 'awful', 'happened', 'actually', 'needed', 'hear', 'say', 'everything', 'said', 'anything', 'else', 'whole', 'world']\n",
            "\n",
            "67 => Original Text: i feel divine and strong\n",
            "Stemmed Tokens: ['feel', 'divin', 'strong']\n",
            "Lemmatized Tokens: ['feel', 'divine', 'strong']\n",
            "\n",
            "68 => Original Text: i can say that i feel amazed\n",
            "Stemmed Tokens: ['say', 'feel', 'amaz']\n",
            "Lemmatized Tokens: ['say', 'feel', 'amazed']\n",
            "\n",
            "69 => Original Text: i actually think i am a fairly authentic person generally i am pretty honest about my opinions desires etc and almost never lie even white lies but when it comes to those deep dark close to home negative feelings in your gut oh how i have repressed them out of fear\n",
            "Stemmed Tokens: ['actual', 'think', 'fairli', 'authent', 'person', 'gener', 'pretti', 'honest', 'opinion', 'desir', 'etc', 'almost', 'never', 'lie', 'even', 'white', 'lie', 'come', 'deep', 'dark', 'close', 'home', 'neg', 'feel', 'gut', 'oh', 'repress', 'fear']\n",
            "Lemmatized Tokens: ['actually', 'think', 'fairly', 'authentic', 'person', 'generally', 'pretty', 'honest', 'opinion', 'desire', 'etc', 'almost', 'never', 'lie', 'even', 'white', 'lie', 'come', 'deep', 'dark', 'close', 'home', 'negative', 'feeling', 'gut', 'oh', 'repressed', 'fear']\n",
            "\n",
            "70 => Original Text: i slept horribly and i m feeling doubtful about everything like why can t i manage to figure out how to save more money\n",
            "Stemmed Tokens: ['slept', 'horribl', 'feel', 'doubt', 'everyth', 'like', 'manag', 'figur', 'save', 'money']\n",
            "Lemmatized Tokens: ['slept', 'horribly', 'feeling', 'doubtful', 'everything', 'like', 'manage', 'figure', 'save', 'money']\n",
            "\n",
            "71 => Original Text: i feel hopeful yet at times not so hopeful\n",
            "Stemmed Tokens: ['feel', 'hope', 'yet', 'time', 'hope']\n",
            "Lemmatized Tokens: ['feel', 'hopeful', 'yet', 'time', 'hopeful']\n",
            "\n",
            "72 => Original Text: i just supposed to read the bible and think well god wants me to feel peaceful so thats what i will do\n",
            "Stemmed Tokens: ['suppos', 'read', 'bibl', 'think', 'well', 'god', 'want', 'feel', 'peac', 'that']\n",
            "Lemmatized Tokens: ['supposed', 'read', 'bible', 'think', 'well', 'god', 'want', 'feel', 'peaceful', 'thats']\n",
            "\n",
            "73 => Original Text: i hated growing up i have no good memories of a life as an innocent child only the feeling of being hated and worthlessness consume the memories\n",
            "Stemmed Tokens: ['hate', 'grow', 'good', 'memori', 'life', 'innoc', 'child', 'feel', 'hate', 'worthless', 'consum', 'memori']\n",
            "Lemmatized Tokens: ['hated', 'growing', 'good', 'memory', 'life', 'innocent', 'child', 'feeling', 'hated', 'worthlessness', 'consume', 'memory']\n",
            "\n",
            "74 => Original Text: i am having really badly cannot wear anything without causing spasms diarrhea or eat more than a few of mouthfuls i am feeling very miserable\n",
            "Stemmed Tokens: ['realli', 'badli', 'wear', 'anyth', 'without', 'caus', 'spasm', 'diarrhea', 'eat', 'mouth', 'feel', 'miser']\n",
            "Lemmatized Tokens: ['really', 'badly', 'wear', 'anything', 'without', 'causing', 'spasm', 'diarrhea', 'eat', 'mouthful', 'feeling', 'miserable']\n",
            "\n",
            "75 => Original Text: when my kid brother broke my reading spectacles\n",
            "Stemmed Tokens: ['kid', 'brother', 'broke', 'read', 'spectacl']\n",
            "Lemmatized Tokens: ['kid', 'brother', 'broke', 'reading', 'spectacle']\n",
            "\n",
            "76 => Original Text: i could feel my mouth water as i devoted all my energy to evoking yelps from his lips\n",
            "Stemmed Tokens: ['could', 'feel', 'mouth', 'water', 'devot', 'energi', 'evok', 'yelp', 'lip']\n",
            "Lemmatized Tokens: ['could', 'feel', 'mouth', 'water', 'devoted', 'energy', 'evoking', 'yelp', 'lip']\n",
            "\n",
            "77 => Original Text: im feeling though that it may be worthwhile to learn the terminology and thus improve my ability to communicate\n",
            "Stemmed Tokens: ['im', 'feel', 'though', 'may', 'worthwhil', 'learn', 'terminolog', 'thu', 'improv', 'abil', 'commun']\n",
            "Lemmatized Tokens: ['im', 'feeling', 'though', 'may', 'worthwhile', 'learn', 'terminology', 'thus', 'improve', 'ability', 'communicate']\n",
            "\n",
            "78 => Original Text: i don t feel afraid i m a nurse i m doing my job\n",
            "Stemmed Tokens: ['feel', 'afraid', 'nurs', 'job']\n",
            "Lemmatized Tokens: ['feel', 'afraid', 'nurse', 'job']\n",
            "\n",
            "79 => Original Text: i was feeling confident that i could work with these kids teach them\n",
            "Stemmed Tokens: ['feel', 'confid', 'could', 'work', 'kid', 'teach']\n",
            "Lemmatized Tokens: ['feeling', 'confident', 'could', 'work', 'kid', 'teach']\n",
            "\n",
            "80 => Original Text: im feeling scared\n",
            "Stemmed Tokens: ['im', 'feel', 'scare']\n",
            "Lemmatized Tokens: ['im', 'feeling', 'scared']\n",
            "\n",
            "81 => Original Text: i was feeling really cute and happy for church on sunday so i thought itd be a good time to take a belly picture\n",
            "Stemmed Tokens: ['feel', 'realli', 'cute', 'happi', 'church', 'sunday', 'thought', 'itd', 'good', 'time', 'take', 'belli', 'pictur']\n",
            "Lemmatized Tokens: ['feeling', 'really', 'cute', 'happy', 'church', 'sunday', 'thought', 'itd', 'good', 'time', 'take', 'belly', 'picture']\n",
            "\n",
            "82 => Original Text: i feel burdened because yuchun and junsu have been doing so well\n",
            "Stemmed Tokens: ['feel', 'burden', 'yuchun', 'junsu', 'well']\n",
            "Lemmatized Tokens: ['feel', 'burdened', 'yuchun', 'junsu', 'well']\n",
            "\n",
            "83 => Original Text: i had to really say that i m feeling remorseful and regretful for what i ve done\n",
            "Stemmed Tokens: ['realli', 'say', 'feel', 'remors', 'regret', 'done']\n",
            "Lemmatized Tokens: ['really', 'say', 'feeling', 'remorseful', 'regretful', 'done']\n",
            "\n",
            "84 => Original Text: im associated with what they do despite how i feel and protest about it whilst reaping the benefits of a relatively peaceful society\n",
            "Stemmed Tokens: ['im', 'associ', 'despit', 'feel', 'protest', 'whilst', 'reap', 'benefit', 'rel', 'peac', 'societi']\n",
            "Lemmatized Tokens: ['im', 'associated', 'despite', 'feel', 'protest', 'whilst', 'reaping', 'benefit', 'relatively', 'peaceful', 'society']\n",
            "\n",
            "85 => Original Text: i have a feeling i will once again walk out pressured to induce but i just have to remain strong in the face of pressure\n",
            "Stemmed Tokens: ['feel', 'walk', 'pressur', 'induc', 'remain', 'strong', 'face', 'pressur']\n",
            "Lemmatized Tokens: ['feeling', 'walk', 'pressured', 'induce', 'remain', 'strong', 'face', 'pressure']\n",
            "\n",
            "86 => Original Text: i feel like i m frolicking away precious time to do something for my future\n",
            "Stemmed Tokens: ['feel', 'like', 'frolick', 'away', 'preciou', 'time', 'someth', 'futur']\n",
            "Lemmatized Tokens: ['feel', 'like', 'frolicking', 'away', 'precious', 'time', 'something', 'future']\n",
            "\n",
            "87 => Original Text: i feel like i have some useful tools\n",
            "Stemmed Tokens: ['feel', 'like', 'use', 'tool']\n",
            "Lemmatized Tokens: ['feel', 'like', 'useful', 'tool']\n",
            "\n",
            "88 => Original Text: i feel like im in some kind of defective shell that prevents me from utilizing who i know myself to be from using the tools i was given\n",
            "Stemmed Tokens: ['feel', 'like', 'im', 'kind', 'defect', 'shell', 'prevent', 'util', 'know', 'use', 'tool', 'given']\n",
            "Lemmatized Tokens: ['feel', 'like', 'im', 'kind', 'defective', 'shell', 'prevents', 'utilizing', 'know', 'using', 'tool', 'given']\n",
            "\n",
            "89 => Original Text: i feel so empty i dont know what i am suppose to do\n",
            "Stemmed Tokens: ['feel', 'empti', 'dont', 'know', 'suppos']\n",
            "Lemmatized Tokens: ['feel', 'empty', 'dont', 'know', 'suppose']\n",
            "\n",
            "90 => Original Text: i genuinely feel for the characters and am keen to uncover every part of the story\n",
            "Stemmed Tokens: ['genuin', 'feel', 'charact', 'keen', 'uncov', 'everi', 'part', 'stori']\n",
            "Lemmatized Tokens: ['genuinely', 'feel', 'character', 'keen', 'uncover', 'every', 'part', 'story']\n",
            "\n",
            "91 => Original Text: im feeling adventurous i might toss in a scoop of protein powder for an extra punch of nutrition\n",
            "Stemmed Tokens: ['im', 'feel', 'adventur', 'might', 'toss', 'scoop', 'protein', 'powder', 'extra', 'punch', 'nutrit']\n",
            "Lemmatized Tokens: ['im', 'feeling', 'adventurous', 'might', 'toss', 'scoop', 'protein', 'powder', 'extra', 'punch', 'nutrition']\n",
            "\n",
            "92 => Original Text: i feel awkward around rose\n",
            "Stemmed Tokens: ['feel', 'awkward', 'around', 'rose']\n",
            "Lemmatized Tokens: ['feel', 'awkward', 'around', 'rose']\n",
            "\n",
            "93 => Original Text: i want to be generous but sometimes i feel greedy\n",
            "Stemmed Tokens: ['want', 'gener', 'sometim', 'feel', 'greedi']\n",
            "Lemmatized Tokens: ['want', 'generous', 'sometimes', 'feel', 'greedy']\n",
            "\n",
            "94 => Original Text: i feel so unsure about this book was the ending\n",
            "Stemmed Tokens: ['feel', 'unsur', 'book', 'end']\n",
            "Lemmatized Tokens: ['feel', 'unsure', 'book', 'ending']\n",
            "\n",
            "95 => Original Text: i really liked it and i have a feeling the beloved would have liked it too except hes away still and missed out\n",
            "Stemmed Tokens: ['realli', 'like', 'feel', 'belov', 'would', 'like', 'except', 'he', 'away', 'still', 'miss']\n",
            "Lemmatized Tokens: ['really', 'liked', 'feeling', 'beloved', 'would', 'liked', 'except', 'he', 'away', 'still', 'missed']\n",
            "\n",
            "96 => Original Text: i feel like talking in a snobbish uppity accent and responding with let me just say a lot while flipping my hair and then trying to pull the cheese wiz out of it\n",
            "Stemmed Tokens: ['feel', 'like', 'talk', 'snobbish', 'uppiti', 'accent', 'respond', 'let', 'say', 'lot', 'flip', 'hair', 'tri', 'pull', 'chees', 'wiz']\n",
            "Lemmatized Tokens: ['feel', 'like', 'talking', 'snobbish', 'uppity', 'accent', 'responding', 'let', 'say', 'lot', 'flipping', 'hair', 'trying', 'pull', 'cheese', 'wiz']\n",
            "\n",
            "97 => Original Text: i don t feel as needy and desperate to prove things\n",
            "Stemmed Tokens: ['feel', 'needi', 'desper', 'prove', 'thing']\n",
            "Lemmatized Tokens: ['feel', 'needy', 'desperate', 'prove', 'thing']\n",
            "\n",
            "98 => Original Text: i feel bad for my mum who carries everything and everyone\n",
            "Stemmed Tokens: ['feel', 'bad', 'mum', 'carri', 'everyth', 'everyon']\n",
            "Lemmatized Tokens: ['feel', 'bad', 'mum', 'carry', 'everything', 'everyone']\n",
            "\n",
            "99 => Original Text: i have a feeling some people really outgoing people must feel like that naturally\n",
            "Stemmed Tokens: ['feel', 'peopl', 'realli', 'outgo', 'peopl', 'must', 'feel', 'like', 'natur']\n",
            "Lemmatized Tokens: ['feeling', 'people', 'really', 'outgoing', 'people', 'must', 'feel', 'like', 'naturally']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string\n",
        "import re\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "# Read data from JSONL file\n",
        "data = []\n",
        "with open(\"emotion_dataset.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuations\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_tokens = [ps.stem(word) for word in filtered_tokens]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "    return stemmed_tokens, lemmatized_tokens\n",
        "\n",
        "# Custom loop of 100 iterations\n",
        "for i in range(100):\n",
        "    # Select a random entry from data\n",
        "    entry = data[i % len(data)]\n",
        "\n",
        "    text = entry[\"text\"]\n",
        "    print(i,\"=> Original Text:\", text)\n",
        "\n",
        "    # Preprocess text\n",
        "    stemmed_tokens, lemmatized_tokens = preprocess_text(text)\n",
        "\n",
        "    print(\"Stemmed Tokens:\", stemmed_tokens)\n",
        "    print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ab4oLy4aKU40"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}